{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Source Link\n",
    "#### https://www.sbert.net/docs/pretrained_models.html\n",
    "#### https://huggingface.co/dbmdz/bert-base-turkish-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dev_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ITEMCODE</th>\n",
       "      <th>ITEMNAME</th>\n",
       "      <th>FICHENO</th>\n",
       "      <th>DATE_</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>LINENETTOTAL</th>\n",
       "      <th>LINENET</th>\n",
       "      <th>BRANCHNR</th>\n",
       "      <th>...</th>\n",
       "      <th>CLIENTCODE</th>\n",
       "      <th>CLIENTNAME</th>\n",
       "      <th>BRANDCODE</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>CATEGORY_NAME1</th>\n",
       "      <th>CATEGORY_NAME2</th>\n",
       "      <th>CATEGORY_NAME3</th>\n",
       "      <th>STARTDATE</th>\n",
       "      <th>ENDDATE</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11738.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>SPRITE 1 LT LIMON AROMALI GAZOZ</td>\n",
       "      <td>18456</td>\n",
       "      <td>2017-01-07 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>467369</td>\n",
       "      <td>Sercan KIZILOK</td>\n",
       "      <td>156</td>\n",
       "      <td>SPRİTE</td>\n",
       "      <td>İÇECEK</td>\n",
       "      <td>GAZLI İÇECEK</td>\n",
       "      <td>GAZOZ</td>\n",
       "      <td>2017-01-08 16:16:11</td>\n",
       "      <td>2017-01-08 16:17:13</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10537.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TOZ SEKER</td>\n",
       "      <td>18105</td>\n",
       "      <td>2017-01-06 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>13.25</td>\n",
       "      <td>12.27</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>131464</td>\n",
       "      <td>İsmet ŞINGIR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>İÇECEK</td>\n",
       "      <td>ÇAY KAHVE</td>\n",
       "      <td>SEKER TATLANDIRICI</td>\n",
       "      <td>2017-01-07 11:04:34</td>\n",
       "      <td>2017-01-07 11:05:37</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11335.0</td>\n",
       "      <td>5979.0</td>\n",
       "      <td>FALIM SAKIZ 5LI NANE</td>\n",
       "      <td>18350</td>\n",
       "      <td>2017-01-03 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>656969</td>\n",
       "      <td>Yağız KUBAL</td>\n",
       "      <td>300</td>\n",
       "      <td>FALIM</td>\n",
       "      <td>GIDA</td>\n",
       "      <td>SAKIZ SEKERLEME</td>\n",
       "      <td>SAKIZ</td>\n",
       "      <td>2017-01-04 14:00:03</td>\n",
       "      <td>2017-01-04 14:01:01</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11336.0</td>\n",
       "      <td>5979.0</td>\n",
       "      <td>FALIM SAKIZ 5LI NANE</td>\n",
       "      <td>18350</td>\n",
       "      <td>2017-01-03 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>656969</td>\n",
       "      <td>Yağız KUBAL</td>\n",
       "      <td>300</td>\n",
       "      <td>FALIM</td>\n",
       "      <td>GIDA</td>\n",
       "      <td>SAKIZ SEKERLEME</td>\n",
       "      <td>SAKIZ</td>\n",
       "      <td>2017-01-04 14:00:03</td>\n",
       "      <td>2017-01-04 14:01:01</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>12808.0</td>\n",
       "      <td>FALIM SAKIZ 5LI CILEK</td>\n",
       "      <td>18005</td>\n",
       "      <td>2017-01-05 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>447336</td>\n",
       "      <td>Habibe AYSAN</td>\n",
       "      <td>300</td>\n",
       "      <td>FALIM</td>\n",
       "      <td>GIDA</td>\n",
       "      <td>SAKIZ SEKERLEME</td>\n",
       "      <td>SAKIZ</td>\n",
       "      <td>2017-01-06 14:00:30</td>\n",
       "      <td>2017-01-06 14:01:03</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  ITEMCODE                         ITEMNAME  FICHENO  \\\n",
       "0  11738.0    5863.0  SPRITE 1 LT LIMON AROMALI GAZOZ    18456   \n",
       "1  10537.0       8.0                        TOZ SEKER    18105   \n",
       "2  11335.0    5979.0             FALIM SAKIZ 5LI NANE    18350   \n",
       "3  11336.0    5979.0             FALIM SAKIZ 5LI NANE    18350   \n",
       "4  10115.0   12808.0            FALIM SAKIZ 5LI CILEK    18005   \n",
       "\n",
       "                 DATE_  AMOUNT  PRICE  LINENETTOTAL  LINENET  BRANCHNR  ...  \\\n",
       "0  2017-01-07 00:00:00     1.0   2.00          2.00     1.85      52.0  ...   \n",
       "1  2017-01-06 00:00:00     5.0   2.65         13.25    12.27       8.0  ...   \n",
       "2  2017-01-03 00:00:00     1.0   0.40          0.40     0.37      40.0  ...   \n",
       "3  2017-01-03 00:00:00     1.0   0.40          0.40     0.37      40.0  ...   \n",
       "4  2017-01-05 00:00:00     1.0   0.40          0.40     0.37      41.0  ...   \n",
       "\n",
       "  CLIENTCODE      CLIENTNAME BRANDCODE   BRAND  CATEGORY_NAME1  \\\n",
       "0     467369  Sercan KIZILOK       156  SPRİTE          İÇECEK   \n",
       "1     131464    İsmet ŞINGIR       NaN     NaN          İÇECEK   \n",
       "2     656969     Yağız KUBAL       300   FALIM            GIDA   \n",
       "3     656969     Yağız KUBAL       300   FALIM            GIDA   \n",
       "4     447336    Habibe AYSAN       300   FALIM            GIDA   \n",
       "\n",
       "    CATEGORY_NAME2      CATEGORY_NAME3            STARTDATE  \\\n",
       "0     GAZLI İÇECEK               GAZOZ  2017-01-08 16:16:11   \n",
       "1        ÇAY KAHVE  SEKER TATLANDIRICI  2017-01-07 11:04:34   \n",
       "2  SAKIZ SEKERLEME               SAKIZ  2017-01-04 14:00:03   \n",
       "3  SAKIZ SEKERLEME               SAKIZ  2017-01-04 14:00:03   \n",
       "4  SAKIZ SEKERLEME               SAKIZ  2017-01-06 14:00:30   \n",
       "\n",
       "               ENDDATE GENDER  \n",
       "0  2017-01-08 16:17:13      E  \n",
       "1  2017-01-07 11:05:37      E  \n",
       "2  2017-01-04 14:01:01      E  \n",
       "3  2017-01-04 14:01:01      E  \n",
       "4  2017-01-06 14:01:03      K  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketsales_df = pd.read_csv('/Users/onursahil/Documents/Developer/docker-elk/logstash/MarketSales.csv')\n",
    "marketsales_df = marketsales_df[marketsales_df['ITEMNAME'].notna()]\n",
    "marketsales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sprite 1 lt limon aromali gazoz',\n",
       " 'toz seker',\n",
       " 'falim sakiz 5li nane',\n",
       " 'falim sakiz 5li cilek',\n",
       " 'f neffis toz seker 2 kg',\n",
       " 'f neffis kesme seker 1 kg',\n",
       " 'kent topitop disney cilek karpuz 6 ad',\n",
       " 'vivident czd fruit swing 14 adet 26 gr',\n",
       " 'lavache quirit ucgen peynir',\n",
       " 'kirmizi biber']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_items = list(marketsales_df.ITEMNAME.unique())\n",
    "market_items = [item.lower() for item in market_items]\n",
    "market_items[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "model = AutoModel.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "\n",
    "item_vector = []\n",
    "for item in market_items[:10]:\n",
    "    inputs = tokenizer(item, return_tensors=\"pt\")\n",
    "#     input_ids = torch.tensor(tokenizer.encode([item])).unsqueeze(0)\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs[0].tolist()\n",
    "    vector = last_hidden_states[0][0]\n",
    "    item_vector.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_vector[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Textual Similarity\n",
    "# bert-large-nli-stsb-mean-tokens\n",
    "# bert-base-nlu-mean-tokens\n",
    "\n",
    "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "corpus_embeddings = embedder.encode(market_items[:10], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4179,  0.4099,  0.0402,  ...,  0.1185, -0.0070,  0.2561],\n",
       "        [-0.2759,  0.0036, -1.1818,  ...,  0.0054,  0.0790,  0.2262],\n",
       "        [-0.7114, -0.0419, -0.2355,  ..., -0.4398,  0.2389,  0.6896],\n",
       "        ...,\n",
       "        [ 0.1882,  0.5506,  0.5495,  ...,  0.1114, -0.1248, -0.2246],\n",
       "        [-0.9741,  0.5369, -0.2189,  ..., -0.5683,  0.1756,  0.5957],\n",
       "        [-0.6019, -0.4196,  0.1363,  ..., -0.5113, -0.5228, -0.3522]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilingual Model\n",
    "# Produces similar embeddings as the bert-base-nli-stsb-mean-token model. \n",
    "# Trained on parallel data for 50+ languages.\n",
    "\n",
    "embedder = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens')\n",
    "corpus_embeddings = embedder.encode(market_items[:10], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2639,  0.1292,  0.2373,  ..., -0.0375, -0.1103,  0.1256],\n",
       "        [ 0.0223,  0.3465,  0.4596,  ..., -0.3474,  0.0508, -0.1547],\n",
       "        [ 0.0666,  0.0711,  0.7633,  ...,  0.1041, -0.1178, -0.0855],\n",
       "        ...,\n",
       "        [ 0.3006,  0.5480,  0.3697,  ...,  0.1443, -0.0921, -0.3718],\n",
       "        [-0.5507,  0.4633,  0.7277,  ...,  0.1900, -0.1192,  0.6806],\n",
       "        [ 0.0205,  0.3860,  0.3547,  ..., -0.1414, -0.0198, -0.0043]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce14c3d5055941698150af9751808baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db34a9347cbf4499a18ed545fa3acaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=433.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bec3b398254de18e1c1f1e166202b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=440473133.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1, 768)\n",
      "(1, 768)\n",
      "İngilizce sınavım beklediğimden kötü geçti düşük seviyeye yerleştim ne yapabilirim?\n",
      "miyim?\n",
      "cos sim:  [[0.80642384]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "model = BertModel.from_pretrained(bert_model_name, return_dict=True)\n",
    "model.eval()\n",
    "\n",
    "text_1 = \"İngilizce sınavım beklediğimden kötü geçti düşük seviyeye yerleştim ne yapabilirim?\"\n",
    "text_2 = \"miyim?\"\n",
    "\n",
    "inputs_1 = tokenizer(text_1, return_tensors=\"pt\")\n",
    "outputs_1 = model(**inputs_1)\n",
    "\n",
    "inputs_2 = tokenizer(text_2, return_tensors=\"pt\")\n",
    "outputs_2 = model(**inputs_2)\n",
    "\n",
    "last_hidden_states_1 = outputs_1.last_hidden_state\n",
    "last_hidden_states_1 = last_hidden_states_1[:,0,:].detach().numpy().reshape(1, -1)\n",
    "\n",
    "last_hidden_states_2 = outputs_2.last_hidden_state\n",
    "last_hidden_states_2 = last_hidden_states_2[:,0,:].detach().numpy().reshape(1, -1)\n",
    "\n",
    "print(last_hidden_states_1.shape)\n",
    "print(last_hidden_states_2.shape)\n",
    "\n",
    "result = cosine_similarity(last_hidden_states_1, last_hidden_states_2)\n",
    "print(text_1)\n",
    "print(text_2)\n",
    "print(\"cos sim: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic Search BERT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "model = AutoModel.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "\n",
    "item_vector_bert = []\n",
    "for item in market_items:\n",
    "    inputs = tokenizer(item, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs[0].tolist()\n",
    "    vector = last_hidden_states[0][0]\n",
    "    item_vector_bert.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(['http://localhost:9200'], http_auth=('elastic', 'changeme'))\n",
    "\n",
    "es_index = {\n",
    "    \"mappings\": {\n",
    "      \"properties\": {\n",
    "        \"message_text\": {\n",
    "          \"type\": \"text\"\n",
    "        },\n",
    "        \"message_vector\": {\n",
    "          \"type\": \"dense_vector\",\n",
    "          \"dims\": 768\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index='marketsales_vectors_bert', body=es_index, ignore=[400])\n",
    "\n",
    "def getQuotes():\n",
    "    for i in range(len(market_items)):\n",
    "        yield {\n",
    "            \"_index\": 'marketsales_vectors_bert',\n",
    "            \"message_text\" : market_items[i],\n",
    "            \"message_vector\" : item_vector_bert[i]\n",
    "         }\n",
    "bulk(client=es, actions = getQuotes(), request_timeout = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"dulasik deterjani\"\n",
    "inputs = tokenizer(input_query, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs[0].tolist()\n",
    "vector = last_hidden_states[0][0]\n",
    "\n",
    "script_query = {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            },\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.query_vector, 'message_vector') + 1.0\",\n",
    "                \"params\": {\n",
    "                    \"query_vector\": vector\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "client = Elasticsearch(hosts=[\"localhost\"], http_auth=('elastic', 'changeme'))\n",
    "\n",
    "response = client.search(\n",
    "    index='marketsales_vectors_bert',\n",
    "    body={\n",
    "        \"query\": script_query\n",
    "    }\n",
    ")\n",
    "\n",
    "all_hits = response['hits']['hits']\n",
    "for i in range(len(all_hits)):\n",
    "    result_text = all_hits[i]['_source']\n",
    "    result_text = result_text['message_text']\n",
    "    vector_list = all_hits[i]['_source']\n",
    "    vector_list = vector_list['message_vector']\n",
    "    print(result_text, vector_list[:10], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
